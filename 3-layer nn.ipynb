{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return (x > 0).astype(float)\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x, axis=1, keepdims=True))\n",
    "    return e_x / np.sum(e_x, axis=1, keepdims=True)\n",
    "\n",
    "def cross_entropy_loss(predictions, labels,reg_lambda):\n",
    "    predictions = np.clip(predictions, 1e-9, 1 - 1e-9)\n",
    "    m = labels.shape[0]\n",
    "    log_probs = -np.log(predictions[np.arange(m), labels])\n",
    "    loss = np.sum(log_probs) / m\n",
    "    return loss\n",
    "\n",
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" Convert vector of labels to one-hot encoding \"\"\"\n",
    "    return np.eye(num_classes)[y]\n",
    "\n",
    "class NeuralNetwork:\n",
    "    def __init__(self, input_size, hidden_size, output_size, activate_model=relu, activation_derivative=relu_derivative):\n",
    "        self.params = {\n",
    "            'W1': np.random.randn(input_size, hidden_size) * np.sqrt(2. / input_size),\n",
    "            'b1': np.zeros(hidden_size),\n",
    "            'W2': np.random.randn(hidden_size, hidden_size) * np.sqrt(2. / hidden_size),\n",
    "            'b2': np.zeros(hidden_size),\n",
    "            'W3': np.random.randn(hidden_size, output_size) * np.sqrt(2. / hidden_size),\n",
    "            'b3': np.zeros(output_size)\n",
    "        }\n",
    "        self.activate_model = activate_model\n",
    "        self.activation_derivative = activation_derivative\n",
    "    \n",
    "    def forward(self, X):\n",
    "        self.cache = {}\n",
    "        # Layer 1\n",
    "        self.cache['Z1'] = np.dot(X, self.params['W1']) + self.params['b1']\n",
    "        self.cache['A1'] = self.activate_model(self.cache['Z1'])\n",
    "        # Layer 2\n",
    "        self.cache['Z2'] = np.dot(self.cache['A1'], self.params['W2']) + self.params['b2']\n",
    "        self.cache['A2'] = self.activate_model(self.cache['Z2'])\n",
    "        # Layer 3\n",
    "        self.cache['Z3'] = np.dot(self.cache['A2'], self.params['W3']) + self.params['b3']\n",
    "        self.cache['A3'] = softmax(self.cache['Z3'])\n",
    "        return self.cache['A3']\n",
    "    \n",
    "    def backward(self, X, y):\n",
    "        m = X.shape[0]\n",
    "        y_true = to_categorical(y, self.params['W3'].shape[1])\n",
    "\n",
    "        # Gradient for Layer 3\n",
    "        dZ3 = self.cache['A3'] - y_true\n",
    "        dW3 = np.dot(self.cache['A2'].T, dZ3) / m\n",
    "        db3 = np.sum(dZ3, axis=0) / m\n",
    "\n",
    "        # Gradient for Layer 2\n",
    "        dA2 = np.dot(dZ3, self.params['W3'].T)\n",
    "        dZ2 = dA2 * self.activation_derivative(self.cache['Z2'])\n",
    "        dW2 = np.dot(self.cache['A1'].T, dZ2) / m\n",
    "        db2 = np.sum(dZ2, axis=0) / m\n",
    "\n",
    "        # Gradient for Layer 1\n",
    "        dA1 = np.dot(dZ2, self.params['W2'].T)\n",
    "        dZ1 = dA1 * self.activation_derivative(self.cache['Z1'])\n",
    "        dW1 = np.dot(X.T, dZ1) / m\n",
    "        db1 = np.sum(dZ1, axis=0) / m\n",
    "\n",
    "        gradients = {'W1': dW1, 'b1': db1, 'W2': dW2, 'b2': db2, 'W3': dW3, 'b3': db3}\n",
    "        return gradients\n",
    "\n",
    "    def update_params(self, gradients, lr, reg_lambda):\n",
    "        for key in self.params:\n",
    "            self.params[key] -= lr * (gradients[key] + reg_lambda * self.params[key])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "\n",
    "    predictions = model.forward(X)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "    accuracy = np.mean(predicted_labels == y)\n",
    "    m = y.shape[0]\n",
    "    y_one_hot = np.eye(model.params['W2'].shape[1])[y]  \n",
    "    log_probs = -np.log(predictions[np.arange(m), y] + 1e-9)  \n",
    "    loss = np.sum(log_probs) / m\n",
    "\n",
    "    return accuracy, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "def train(X_train, y_train, X_val, y_val, model, epochs, batch_size, lr, reg_lambda):\n",
    "    n_batches = int(np.ceil(X_train.shape[0] / batch_size))\n",
    "    best_val_acc = 0\n",
    "    best_params = {}\n",
    "    train_losses = []\n",
    "    val_accuracys=[]\n",
    "    val_losses=[]\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # Shuffle dataset\n",
    "        indices = np.arange(X_train.shape[0])\n",
    "        np.random.shuffle(indices)\n",
    "        X_train = X_train[indices]\n",
    "        y_train = y_train[indices]\n",
    "        epoch_losses = []\n",
    "        for i in range(n_batches):\n",
    "            start_idx = i * batch_size\n",
    "            end_idx = min((i + 1) * batch_size, X_train.shape[0])\n",
    "            \n",
    "            X_batch = X_train[start_idx:end_idx]\n",
    "            y_batch = y_train[start_idx:end_idx]\n",
    "            # Forward and backward propagation\n",
    "            output = model.forward(X_batch)\n",
    "            loss=cross_entropy_loss(output,y_batch,reg_lambda)\n",
    "            epoch_losses.append(loss)\n",
    "            gradients = model.backward(X_batch, y_batch)\n",
    "            \n",
    "            # Update weights\n",
    "            model.update_params(gradients, lr,reg_lambda)\n",
    "        average_loss = np.mean(epoch_losses)\n",
    "        train_losses.append(average_loss)\n",
    "        # Validation accuracy\n",
    "        val_acc,val_loss=evaluate_model(model,X_val,y_val)\n",
    "        print(f'Epoch {epoch + 1}, Train Loss: {average_loss:.4f}')\n",
    "        print(f'Epoch {epoch + 1}, Validation Accuracy: {val_acc:.4f}')\n",
    "        val_accuracys.append(val_acc)\n",
    "        val_losses.append(val_loss)\n",
    "        # Check if we need to update the best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_params = model.params.copy()\n",
    "    print(f'Epoch {epoch + 1}, Best Validation Accuracy: {best_val_acc:.4f}')\n",
    "    \n",
    "    model.params = best_params\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(train_losses, label='Training Loss')\n",
    "    plt.plot(val_losses, label='Validation Loss')\n",
    "    plt.title('Loss over epochs')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(val_accuracys)\n",
    "    plt.title('Validation Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/OQEPoAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAmjUlEQVR4nO3de3CV9Z3H8c9JSE4u5ELIvQZMREDk0hYlpSLGkiGkLSvKbr3NLDgdHG1wVNbLZldB3c5kxdYyWhY6u1XqCGjdFazWoaNgwnQ3wIKwDK2ykA0CkgvESU7uCZxn/8iY3SMJ+Ptxkl8u79fMmTHnnE+e33nyxA/nnCff4/M8zxMAAIMswvUCAACjEwUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEXKETJ07I5/PpZz/7Wdi+Z3l5uXw+n8rLy8P2PYGhhgLCqLRp0yb5fD7t37/f9VIGxNVXXy2fz9fn5dprr3W9PECSNMb1AgCE37p169TS0hJy3WeffaannnpKCxcudLQqIBQFBIxAS5Ysuei6n/70p5Kke++9d5BXA/SNl+CAfnR1dWn16tWaPXu2kpKSFB8fr5tvvlkfffRRv5lf/OIXmjhxomJjY3XLLbfoyJEjF93n008/1V/+5V8qJSVFMTExuuGGG/S73/3usutpa2vTp59+qnPnzlk9ni1btig3N1ff/e53rfJAuFFAQD8CgYD+5V/+RQUFBXr++ef1zDPP6OzZsyoqKtKhQ4cuuv9rr72ml156SSUlJSotLdWRI0f0ve99T3V1db33+dOf/qTvfOc7+uSTT/S3f/u3+vnPf674+HgtWbJE27Ztu+R69u3bp+uuu06//OUvjR/LwYMH9cknn+iee+4xzgIDhZfggH6MGzdOJ06cUHR0dO91K1as0NSpU/Xyyy/r17/+dcj9jx8/rmPHjukb3/iGJGnRokXKz8/X888/rxdffFGS9PDDD2vChAn6z//8T/n9fknST37yE82bN09PPvmkbr/99gF5LJs3b5bEy28YWngGBPQjMjKyt3yCwaC++OILnT9/XjfccIM+/vjji+6/ZMmS3vKRpDlz5ig/P1/vv/++JOmLL77Qrl279KMf/UjNzc06d+6czp07p4aGBhUVFenYsWP6/PPP+11PQUGBPM/TM888Y/Q4gsGg3njjDX3rW9/SddddZ5QFBhIFBFzCb37zG82cOVMxMTEaP3680tLS9Pvf/15NTU0X3bev05snT56sEydOSOp5huR5np5++mmlpaWFXNasWSNJqq+vD/tjqKio0Oeff86zHww5vAQH9OP111/X8uXLtWTJEj3++ONKT09XZGSkysrKVFVVZfz9gsGgJOmxxx5TUVFRn/eZNGnSFa25L5s3b1ZERITuvvvusH9v4EpQQEA//vVf/1V5eXl6++235fP5eq//8tnKVx07duyi6/77v/9bV199tSQpLy9PkhQVFaXCwsLwL7gPnZ2d+rd/+zcVFBQoOzt7ULYJfF28BAf0IzIyUpLkeV7vdXv37lVlZWWf99++fXvIezj79u3T3r17VVxcLElKT09XQUGBfvWrX6mmpuai/NmzZy+5HpvTsN9//301Njby8huGJJ4BYVR75ZVXtGPHjouuf/jhh/XDH/5Qb7/9tm6//Xb94Ac/UHV1tTZu3Khp06ZdNGVA6nn5bN68eXrwwQfV2dmpdevWafz48XriiSd677N+/XrNmzdPM2bM0IoVK5SXl6e6ujpVVlbq9OnT+q//+q9+17pv3z7deuutWrNmzdc+EWHz5s3y+/1aunTp17o/MJgoIIxqGzZs6PP65cuXa/ny5aqtrdWvfvUr/eEPf9C0adP0+uuv66233upzSOhf//VfKyIiQuvWrVN9fb3mzJmjX/7yl8rKyuq9z7Rp07R//349++yz2rRpkxoaGpSenq5vfetbWr16dVgfWyAQ0O9//3v94Ac/UFJSUli/NxAOPu//v74AAMAg4T0gAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcGHJ/BxQMBnXmzBklJCSEjD8BAAwPnuepublZ2dnZiojo/3nOkCugM2fOKCcnx/UyAABX6NSpU7rqqqv6vX3IFVBCQoLrJWAEePzxx61y06dPN878/088/br6+jiHy0lMTDTOLFy40Dgj2e2/Dz/80GpbGLku9//zASug9evX64UXXlBtba1mzZqll19+WXPmzLlsjpfdhg+bn9VgDd748tNGTcXFxRlnYmNjjTOdnZ3GmZiYGOOM7T/ooqKirHIY2r8Xg+1y+2JATkJ48803tWrVKq1Zs0Yff/yxZs2apaKiogH5sC0AwPA0IAX04osvasWKFbrvvvs0bdo0bdy4UXFxcXrllVcGYnMAgGEo7AXU1dWlAwcOhHzgVkREhAoLC/v8HJXOzk4FAoGQCwBg5At7AZ07d04XLlxQRkZGyPUZGRmqra296P5lZWVKSkrqvXAGHACMDs7/ELW0tFRNTU29l1OnTrleEgBgEIT9LLjU1FRFRkZedGpqXV2dMjMzL7q/3++3PmMJADB8hf0ZUHR0tGbPnq2dO3f2XhcMBrVz507NnTs33JsDAAxTA/J3QKtWrdKyZct0ww03aM6cOVq3bp1aW1t13333DcTmAADD0IAU0J133qmzZ89q9erVqq2t1Te/+U3t2LHjohMTAACjl88bYn+CGwgElJSU5HoZQwJ/Ud3ju9/9rnFm9+7dVtsqKSkxzrS3txtnbI5xm+kJf//3f2+ckXpeNje1fPly40xFRYVxBsNHU1PTJUdIOT8LDgAwOlFAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACYaRWrAZEmpjsH40Y8eOtco99NBDxpni4mLjTG5urnEmEAgYZyTp008/Nc78xV/8hXHm9OnTxpkJEyYYZw4dOmSckaS2tjbjTFpamnFm3Lhxxpmf/exnxpmNGzcaZySpubnZKoceDCMFAAxJFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOME0bAs207AHazc/8cQTxpk777zTalsJCQnGmY6ODuPM+fPnjTOtra3GGcluCnRsbKxx5pvf/KZx5rPPPjPOnDx50jgjSTExMVY5UykpKcaZ9vZ240x0dLRxRpJ+/vOfG2e2bt1qta2RiGnYAIAhiQICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOMIx0CFu6dKlx5oUXXjDOVFdXG2ckKRgMGmdshlzaDDC1GZQq2Q0WtdlWamqqcWb//v3GGZvHI0lRUVHGmTNnzhhnsrKyjDM1NTXGmZycHOOMJI0ZM8Y4M3fuXONMS0uLcWY4YBgpAGBIooAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIAT5pP2MGh+9KMfGWfOnj1rnLEZKirZDdRsbm42zgzmcNrTp08bZyZNmmSc+Z//+R/jTHt7+6BkJCktLc04ExkZaZyxPfZMNTQ0WOWSk5ONM4sXLzbObN261TgzEvAMCADgBAUEAHAi7AX0zDPPyOfzhVymTp0a7s0AAIa5AXkP6Prrr9eHH374fxux+FAnAMDINiDNMGbMGGVmZg7EtwYAjBAD8h7QsWPHlJ2drby8PN177706efJkv/ft7OxUIBAIuQAARr6wF1B+fr42bdqkHTt2aMOGDaqurtbNN9/c7+m3ZWVlSkpK6r3YfnY7AGB4CXsBFRcX66/+6q80c+ZMFRUV6f3331djY6N++9vf9nn/0tJSNTU19V5OnToV7iUBAIagAT87IDk5WZMnT9bx48f7vN3v98vv9w/0MgAAQ8yA/x1QS0uLqqqqlJWVNdCbAgAMI2EvoMcee0wVFRU6ceKE/uM//kO33367IiMjdffdd4d7UwCAYSzsL8GdPn1ad999txoaGpSWlqZ58+Zpz549VrOlAAAjV9gL6I033gj3txy1MjIyjDOe5xlnWltbjTOSlJCQYJyxGQqZl5dnnKmqqjLOSNKECROMM/X19cYZm/c9fT6fcSYiwu5FDps/h7A5Hrq6uowzY8eONc7ExMQYZyS7Aav8DeTXxyw4AIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHBiwD+QDj1sBihGR0cbZzo6OowzKSkpxhnJbn2DNYTT9kMObXI2A1ZtBnfaDNS0GaYpSRcuXDDOjBlj/r8Tm6GnUVFRxpnY2FjjjGR3jNsMzx2teAYEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJ5iGPUimT59unLGZLhwRYf5vCpvtSFJjY6NxxmbKcldXl3Gmra3NOCNJra2txhmb9dnsh/b2duNMMBg0zkh2U7Q9zzPO2Exvt5kKbvMzkuweU1JSktW2RiOeAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAEwwjHSTXX3+9caazs9M4Ex0dbZyxGWAqSVFRUVY5U+fPnzfO2OwH29xgDe4cO3bsoGzHlt/vN87YrM9mOz6fzzgj2Q3qnTJlitW2RiOeAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAEwwjHSQzZ840ztgMxrQZ7hgbG2uckaTW1lbjTFxcnHEmISHBOFNfX2+csXXhwgXjjM1AzTNnzgzKdiS7Qbjjxo0zzpw9e9Y4Ex8fb5xpb283ztjmJk+ebLWt0YhnQAAAJyggAIATxgW0e/duLV68WNnZ2fL5fNq+fXvI7Z7nafXq1crKylJsbKwKCwt17NixcK0XADBCGBdQa2urZs2apfXr1/d5+9q1a/XSSy9p48aN2rt3r+Lj41VUVKSOjo4rXiwAYOQwPgmhuLhYxcXFfd7meZ7WrVunp556Srfddpsk6bXXXlNGRoa2b9+uu+6668pWCwAYMcL6HlB1dbVqa2tVWFjYe11SUpLy8/NVWVnZZ6azs1OBQCDkAgAY+cJaQLW1tZKkjIyMkOszMjJ6b/uqsrIyJSUl9V5ycnLCuSQAwBDl/Cy40tJSNTU19V5OnTrlekkAgEEQ1gLKzMyUJNXV1YVcX1dX13vbV/n9fiUmJoZcAAAjX1gLKDc3V5mZmdq5c2fvdYFAQHv37tXcuXPDuSkAwDBnfBZcS0uLjh8/3vt1dXW1Dh06pJSUFE2YMEGPPPKIfvrTn+raa69Vbm6unn76aWVnZ2vJkiXhXDcAYJgzLqD9+/fr1ltv7f161apVkqRly5Zp06ZNeuKJJ9Ta2qr7779fjY2Nmjdvnnbs2KGYmJjwrRoAMOwZF1BBQcElB176fD4999xzeu65565oYSONzdl9XV1dxhmb4Yk+n884I0mRkZHGGZvT7G2GstoM05Ts9p/NAFgbNtuxGf4q2e0/m39k2mRsBqyeP3/eOCPZDZq1/X0ajZyfBQcAGJ0oIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwwngaNux0d3cPynZiY2ONM+np6Vbbqq+vN87YTGeOj483zowdO9Y4Y5trbm42zthMOredbG3DZuK0zXR0m2nTNhPLbfedzc92sKaCd3R0GGeGGp4BAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATDCMdJNnZ2caZ8+fPG2dshkj6fD7jjCS1tbUZZzzPM87Y7IfOzk7jjGT3mGwyNpqamowzNvtOsht02draapyxOfZaWlqMMzbDPiUpOjraOFNTU2OcSU1NNc6cPn3aODPU8AwIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJxgGOkIc+HCBeNMQ0OD1ba6urqMM5GRkcYZm8GisbGxxhnJbmilzQDYMWPMf/USExONMzZrk+x+Tjbbshn2GRcXZ5yx+b2QpISEBOOMzfoyMzONMwwjBQDAEgUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcYBjpIMnJyTHOVFdXG2ciIsz/TZGammqckaTGxkbjjM2Qy/j4eONMIBAwzkjS+fPnrXKmbB5TU1OTcSYtLc04I0mtra3GGZtBrt3d3cYZm59RcnKyccaWze+F7e/gcMczIACAExQQAMAJ4wLavXu3Fi9erOzsbPl8Pm3fvj3k9uXLl8vn84VcFi1aFK71AgBGCOMCam1t1axZs7R+/fp+77No0SLV1NT0XrZu3XpFiwQAjDzGJyEUFxeruLj4kvfx+/1Wn/AHABg9BuQ9oPLycqWnp2vKlCl68MEHL/mRz52dnQoEAiEXAMDIF/YCWrRokV577TXt3LlTzz//vCoqKlRcXNzvZ7KXlZUpKSmp92JzujIAYPgJ+98B3XXXXb3/PWPGDM2cOVPXXHONysvLtWDBgovuX1paqlWrVvV+HQgEKCEAGAUG/DTsvLw8paam6vjx433e7vf7lZiYGHIBAIx8A15Ap0+fVkNDg7KysgZ6UwCAYcT4JbiWlpaQZzPV1dU6dOiQUlJSlJKSomeffVZLly5VZmamqqqq9MQTT2jSpEkqKioK68IBAMObcQHt379ft956a+/XX75/s2zZMm3YsEGHDx/Wb37zGzU2Nio7O1sLFy7UP/zDP8jv94dv1QCAYc+4gAoKCuR5Xr+3/+EPf7iiBY1U7e3txhmbQY2xsbHGmf7en7uc5uZm44zNe3w2gzFt9Xe25qV0dXUZZ2yOh0v93vXHdriqzWDRuLg444zN8NzB2ne220pPTzfO2AzpHQmYBQcAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnwv6R3OibzdRfG/Hx8caZvXv3Wm1r8uTJxplx48YZZ2wmVLe0tBhnJLsp0DYTyG0kJycbZ6Kjo622ZTM9OhgMGmdsHtO+ffuMMzk5OcYZyW6auM0+Zxo2AACDiAICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOMIx0kNgMKBwzxvzHYzPU8IMPPjDOSNLMmTONMzbDHW20t7db5QKBgHHGZnBnY2Ojcaajo8M4YzvksqmpyTgzduxY44zNkN7Ozs5ByUjS+PHjjTM2+87n8xlnRgKeAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAEwwjHSTd3d3GGZtBkjbbiYuLM85IUnx8vHHmiy++MM7Y7IfU1FTjjGQ3UPPs2bPGmSlTphhngsGgcSYmJsY4I0ldXV1WOVM267MZYPqnP/3JOCNJ06ZNM85kZ2cbZ2yOu5GAZ0AAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJCggA4ATDSAdJbW2tccZm+GRsbKxxprGx0TgjSWlpacaZzs5O48yYMeaHaWtrq3FGkjo6OowzWVlZxhmboaz19fXGGZtjSLIfUGvK8zzjTGJi4gCspG9RUVHGGZtjb7D291DDMyAAgBMUEADACaMCKisr04033qiEhASlp6dryZIlOnr0aMh9Ojo6VFJSovHjx2vs2LFaunSp6urqwrpoAMDwZ1RAFRUVKikp0Z49e/TBBx+ou7tbCxcuDHnN89FHH9W7776rt956SxUVFTpz5ozuuOOOsC8cADC8Gb27u2PHjpCvN23apPT0dB04cEDz589XU1OTfv3rX2vLli363ve+J0l69dVXdd1112nPnj36zne+E76VAwCGtSt6D6ipqUmSlJKSIkk6cOCAuru7VVhY2HufqVOnasKECaqsrOzze3R2dioQCIRcAAAjn3UBBYNBPfLII7rppps0ffp0ST2nGkdHRys5OTnkvhkZGf2ehlxWVqakpKTeS05Oju2SAADDiHUBlZSU6MiRI3rjjTeuaAGlpaVqamrqvZw6deqKvh8AYHiw+kPUlStX6r333tPu3bt11VVX9V6fmZmprq4uNTY2hjwLqqurU2ZmZp/fy+/3y+/32ywDADCMGT0D8jxPK1eu1LZt27Rr1y7l5uaG3D579mxFRUVp586dvdcdPXpUJ0+e1Ny5c8OzYgDAiGD0DKikpERbtmzRO++8o4SEhN73dZKSkhQbG6ukpCT9+Mc/1qpVq5SSkqLExEQ99NBDmjt3LmfAAQBCGBXQhg0bJEkFBQUh17/66qtavny5JOkXv/iFIiIitHTpUnV2dqqoqEj/9E//FJbFAgBGDqMC+jqDA2NiYrR+/XqtX7/eelHoceHCBeOMzTDN+Ph444xkN4TTZhhpd3e3ccZmiKRkN/jU5ufU1dVlnMnLyzPOjB071jgj2e2HEydOGGdSU1ONMzY/W9uBuzbHns/nM85ERIzOqWij81EDAJyjgAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACatPRB3tbKZH20zItZlIbDP19/PPPzfOSLL6JNuzZ88aZ8aPH2+csZ2GnZaWZpyx2X82U6Dr6+uNMydPnjTOSD2f8WVq9+7dxpn77rvPONPQ0GCcqampMc5I0rx584wzLS0txpn+PjF6pOMZEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4wTBSC1dffbVxxmY4ps0wUpvMvn37jDOS1NbWZpxpbW01zjQ3NxtnbIdPZmVlGWcCgYBx5osvvjDOJCcnG2eOHTtmnJGkW2+91TgzefJk40xcXJxx5s033zTOjBs3zjgjSdnZ2caZ6upq44zNgOORgGdAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADACQoIAOAEw0gtxMbGGmdshnBGRkYaZ+rq6owztl555RXjzLe//W3jjM2wT5vBnZLdPvf5fMaZnJwc44zN4E6bIbiS1NXVZZzp7Ow0ztj8bA8fPmycmT17tnFGshvmajNYNBgMGmdGAp4BAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATDCO1EBMTY5xJS0szzkRHRxtnKisrjTO2HnroIePMP//zPxtnJk2aZJzp6OgwzkjSmDHmvxIJCQnGGZthnzZDTz3PM85Ido9p+vTpxpk77rjDOGOjvb3dKmfzu97W1macsfn/w0jAMyAAgBMUEADACaMCKisr04033qiEhASlp6dryZIlOnr0aMh9CgoK5PP5Qi4PPPBAWBcNABj+jAqooqJCJSUl2rNnjz744AN1d3dr4cKFF33Y2ooVK1RTU9N7Wbt2bVgXDQAY/ozecd2xY0fI15s2bVJ6eroOHDig+fPn914fFxenzMzM8KwQADAiXdF7QE1NTZKklJSUkOs3b96s1NRUTZ8+XaWlpZc8K6Szs1OBQCDkAgAY+axPww4Gg3rkkUd00003hZx+ec8992jixInKzs7W4cOH9eSTT+ro0aN6++23+/w+ZWVlevbZZ22XAQAYpqwLqKSkREeOHNEf//jHkOvvv//+3v+eMWOGsrKytGDBAlVVVemaa6656PuUlpZq1apVvV8HAgHl5OTYLgsAMExYFdDKlSv13nvvaffu3brqqqsued/8/HxJ0vHjx/ssIL/fL7/fb7MMAMAwZlRAnufpoYce0rZt21ReXq7c3NzLZg4dOiRJysrKslogAGBkMiqgkpISbdmyRe+8844SEhJUW1srSUpKSlJsbKyqqqq0ZcsWff/739f48eN1+PBhPfroo5o/f75mzpw5IA8AADA8GRXQhg0bJPX8sen/9+qrr2r58uWKjo7Whx9+qHXr1qm1tVU5OTlaunSpnnrqqbAtGAAwMhi/BHcpOTk5qqiouKIFAQBGB6ZhW7CZmGwzldjm5IyDBw8aZwbTihUrjDOLFy82zlx33XXGGUm65ZZbjDPx8fHGme7ubuOMzfHQ0NBgnJGk119/3Tjzu9/9zmpbg+HPf/6zVS4xMdE48/nnnxtn0tPTjTMjAcNIAQBOUEAAACcoIACAExQQAMAJCggA4AQFBABwggICADhBAQEAnKCAAABOUEAAACcoIACAExQQAMAJhpFaqK6uNs7YDAlNSEgwzlRVVRlnbEVGRhpnLly4YJx59913ByUjSWvXrrXKwY7P5zPO2Az2tXXgwAHjTFRUlHFm165dxpmRgGdAAAAnKCAAgBMUEADACQoIAOAEBQQAcIICAgA4QQEBAJyggAAATlBAAAAnKCAAgBMUEADAiSE3C24w5zzZCgaDxpn29nbjzGDNWrM1HH5WGNqG+jHU1tZmnLGZBdfV1WWcGQ4u9/P1eUPsCDh9+rRycnJcLwMAcIVOnTqlq666qt/bh1wBBYNBnTlzRgkJCRdNyg0EAsrJydGpU6eUmJjoaIXusR96sB96sB96sB96DIX94HmempublZ2drYiI/t/pGXIvwUVERFyyMSUpMTFxVB9gX2I/9GA/9GA/9GA/9HC9H5KSki57H05CAAA4QQEBAJwYVgXk9/u1Zs0a+f1+10txiv3Qg/3Qg/3Qg/3QYzjthyF3EgIAYHQYVs+AAAAjBwUEAHCCAgIAOEEBAQCcoIAAAE4MmwJav369rr76asXExCg/P1/79u1zvaRB98wzz8jn84Vcpk6d6npZA2737t1avHixsrOz5fP5tH379pDbPc/T6tWrlZWVpdjYWBUWFurYsWNuFjuALrcfli9fftHxsWjRIjeLHSBlZWW68cYblZCQoPT0dC1ZskRHjx4NuU9HR4dKSko0fvx4jR07VkuXLlVdXZ2jFQ+Mr7MfCgoKLjoeHnjgAUcr7tuwKKA333xTq1at0po1a/Txxx9r1qxZKioqUn19veulDbrrr79eNTU1vZc//vGPrpc04FpbWzVr1iytX7++z9vXrl2rl156SRs3btTevXsVHx+voqIidXR0DPJKB9bl9oMkLVq0KOT42Lp16yCucOBVVFSopKREe/bs0QcffKDu7m4tXLhQra2tvfd59NFH9e677+qtt95SRUWFzpw5ozvuuMPhqsPv6+wHSVqxYkXI8bB27VpHK+6HNwzMmTPHKykp6f36woULXnZ2tldWVuZwVYNvzZo13qxZs1wvwylJ3rZt23q/DgaDXmZmpvfCCy/0XtfY2Oj5/X5v69atDlY4OL66HzzP85YtW+bddtttTtbjSn19vSfJq6io8Dyv52cfFRXlvfXWW733+eSTTzxJXmVlpatlDriv7gfP87xbbrnFe/jhh90t6msY8s+Aurq6dODAARUWFvZeFxERocLCQlVWVjpcmRvHjh1Tdna28vLydO+99+rkyZOul+RUdXW1amtrQ46PpKQk5efnj8rjo7y8XOnp6ZoyZYoefPBBNTQ0uF7SgGpqapIkpaSkSJIOHDig7u7ukONh6tSpmjBhwog+Hr66H760efNmpaamavr06SotLbX6fKOBNOSmYX/VuXPndOHCBWVkZIRcn5GRoU8//dTRqtzIz8/Xpk2bNGXKFNXU1OjZZ5/VzTffrCNHjighIcH18pyora2VpD6Pjy9vGy0WLVqkO+64Q7m5uaqqqtLf/d3fqbi4WJWVlVYfbjjUBYNBPfLII7rppps0ffp0ST3HQ3R0tJKTk0PuO5KPh772gyTdc889mjhxorKzs3X48GE9+eSTOnr0qN5++22Hqw015AsI/6e4uLj3v2fOnKn8/HxNnDhRv/3tb/XjH//Y4cowFNx11129/z1jxgzNnDlT11xzjcrLy7VgwQKHKxsYJSUlOnLkyKh4H/RS+tsP999/f+9/z5gxQ1lZWVqwYIGqqqp0zTXXDPYy+zTkX4JLTU1VZGTkRWex1NXVKTMz09Gqhobk5GRNnjxZx48fd70UZ748Bjg+LpaXl6fU1NQReXysXLlS7733nj766KOQzw/LzMxUV1eXGhsbQ+4/Uo+H/vZDX/Lz8yVpSB0PQ76AoqOjNXv2bO3cubP3umAwqJ07d2ru3LkOV+ZeS0uLqqqqlJWV5XopzuTm5iozMzPk+AgEAtq7d++oPz5Onz6thoaGEXV8eJ6nlStXatu2bdq1a5dyc3NDbp89e7aioqJCjoejR4/q5MmTI+p4uNx+6MuhQ4ckaWgdD67Pgvg63njjDc/v93ubNm3y/vznP3v333+/l5yc7NXW1rpe2qD6m7/5G6+8vNyrrq72/v3f/90rLCz0UlNTvfr6etdLG1DNzc3ewYMHvYMHD3qSvBdffNE7ePCg99lnn3me53n/+I//6CUnJ3vvvPOOd/jwYe+2227zcnNzvfb2dscrD69L7Yfm5mbvscce8yorK73q6mrvww8/9L797W971157rdfR0eF66WHz4IMPeklJSV55eblXU1PTe2lra+u9zwMPPOBNmDDB27Vrl7d//35v7ty53ty5cx2uOvwutx+OHz/uPffcc97+/fu96upq75133vHy8vK8+fPnO155qGFRQJ7neS+//LI3YcIELzo62pszZ463Z88e10sadHfeeaeXlZXlRUdHe9/4xje8O++80zt+/LjrZQ24jz76yJN00WXZsmWe5/Wciv300097GRkZnt/v9xYsWOAdPXrU7aIHwKX2Q1tbm7dw4UIvLS3Ni4qK8iZOnOitWLFixP0jra/HL8l79dVXe+/T3t7u/eQnP/HGjRvnxcXFebfffrtXU1PjbtED4HL74eTJk978+fO9lJQUz+/3e5MmTfIef/xxr6mpye3Cv4LPAwIAODHk3wMCAIxMFBAAwAkKCADgBAUEAHCCAgIAOEEBAQCcoIAAAE5QQAAAJyggAIATFBAAwAkKCADgxP8C0i1RYf2V4vQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "((48000, 784), (12000, 784), (10000, 784))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import struct\n",
    "def load_mnist(path, kind='train'):\n",
    "    labels_path = os.path.join(path, f'{kind}-labels-idx1-ubyte')\n",
    "    images_path = os.path.join(path, f'{kind}-images-idx3-ubyte')\n",
    "\n",
    "    with open(labels_path, 'rb') as lbpath:\n",
    "        magic, n = struct.unpack('>II', lbpath.read(8))\n",
    "        labels = np.fromfile(lbpath, dtype=np.uint8)\n",
    "\n",
    "    with open(images_path, 'rb') as imgpath:\n",
    "        magic, num, rows, cols = struct.unpack(\">IIII\", imgpath.read(16))\n",
    "        images = np.fromfile(imgpath, dtype=np.uint8).reshape(len(labels), 784)\n",
    "\n",
    "    return images, labels\n",
    "train_images, train_labels = load_mnist('data', kind='train')\n",
    "test_images, test_labels = load_mnist('data', kind='t10k')\n",
    "train_images, train_labels = load_mnist('data', kind='train')\n",
    "\n",
    "num_validation_samples = int(0.2 * train_images.shape[0])\n",
    "\n",
    "indices = np.arange(train_images.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "train_images = train_images[indices]\n",
    "train_labels = train_labels[indices]\n",
    "\n",
    "val_images = train_images[:num_validation_samples]\n",
    "val_labels = train_labels[:num_validation_samples]\n",
    "\n",
    "train_images = train_images[num_validation_samples:]\n",
    "train_labels = train_labels[num_validation_samples:]\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(train_images[0].reshape(28, 28), cmap='gray')\n",
    "plt.title(f'Label: {train_labels[1]}')\n",
    "plt.show()\n",
    "\n",
    "train_images.shape,val_images.shape,test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def grid_search(X_train, y_train, X_val, y_val, input_size, output_size):\n",
    "    learning_rates = [0.0001,0.00005]\n",
    "    hidden_sizes = [100, 150,200]\n",
    "    reg_lambdas = [0.1,0.2]\n",
    "    batch_sizes=[32,64]\n",
    "    best_val_acc = 0\n",
    "    best_params = {}\n",
    "    results = []\n",
    "\n",
    "# 参数搜索\n",
    "    for lr in learning_rates:\n",
    "        for hidden_size in hidden_sizes:\n",
    "            for reg_lambda in reg_lambdas:\n",
    "                for batch_size in batch_sizes:\n",
    "                    model = NeuralNetwork(input_size=input_size, hidden_size=hidden_size, output_size=output_size)\n",
    "                    print(f\"Training with lr={lr}, hidden_size={hidden_size}, reg_lambda={reg_lambda}, batch_size={batch_size}\")\n",
    "                    train(X_train, y_train, X_val, y_val, model, epochs=30, batch_size=batch_size, lr=lr, reg_lambda=reg_lambda)\n",
    "                    val_acc, _ = evaluate_model(model, X_val, y_val)\n",
    "                    results.append((lr, hidden_size, reg_lambda, batch_size, val_acc))\n",
    "                    print(f\"Validation accuracy: {val_acc:.4f}\")\n",
    "                    if val_acc > best_val_acc:\n",
    "                        best_val_acc = val_acc\n",
    "                        best_params = {'lr': lr, 'hidden_size': hidden_size, 'reg_lambda': reg_lambda, 'batch_size': batch_size}\n",
    "                        print(f\"New best params found: {best_params}, val_acc: {val_acc:.4f}\")\n",
    "\n",
    "    # 保存或返回结果\n",
    "    return best_params, best_val_acc, results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params, best_accuracy,result=grid_search(train_images,train_labels,val_images, val_labels, input_size=784, output_size=10)\n",
    "print(\"result:\",result)\n",
    "print(\"Best params:\", best_params)\n",
    "print(\"Best validation accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=NeuralNetwork(input_size=784,hidden_size=200,output_size=10)\n",
    "train(train_images,train_labels,test_images,test_labels,model,epochs=100,batch_size=32,lr=0.0001,reg_lambda=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix\n",
    "\n",
    "predictions = model.forward(test_images)\n",
    "\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "\n",
    "precision = precision_score(test_labels, predicted_labels, average='macro')\n",
    "\n",
    "f1 = f1_score(test_labels, predicted_labels, average='macro')\n",
    "\n",
    "conf_matrix = confusion_matrix(test_labels, predicted_labels)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('model_params.pkl', 'wb') as f:\n",
    "    pickle.dump(model.params, f)\n",
    "\n",
    "with open('model_params.pkl', 'rb') as f:\n",
    "    loaded_params = pickle.load(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
