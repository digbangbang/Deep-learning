# 实验报告：构建三层神经网络进行图像分类

- [**代码**](https://github.com/digbangbang/Deep-learning)
- [**模型权重**](https://drive.google.com/file/d/1K6MOTVBah5wLQgw6Hzprb3VoSAo8pLWX/view?usp=drive_link)


## 一、实验目的

本实验的目的是通过构建一个三层神经网络分类器，深入学习和实践神经网络中的基本概念。这些概念包括但不限于前向传播、反向传播、激活函数、损失函数及其梯度计算等。此外，实验旨在加深对神经网络超参数调优和优化器工作机制的理解。

## 二、实验环境

- **编程语言**：Python 3.10
- **第三方库**：NumPy, scikit-learn
- **数据集**：Fashion-MNIST

## 三、模型设计

### 3.1 网络结构

构建的三层神经网络包含：
- **输入层**：接受 784 维输入特征（Fashion-MNIST 图像展平后的尺寸）。
- **隐藏层**：自定义节点数，采用 ReLU 激活函数。
- **输出层**：10 个节点（对应 10 个类别），使用 Softmax 激活函数进行多分类。

### 3.2 损失函数

选用交叉熵损失函数，并结合 L2 正则化以避免模型过拟合。

## 四、实验过程

### 4.1 数据准备

加载 Fashion-MNIST 数据集，包含 70,000 个灰度图像，每个图像 28x28 像素，分为 10 个类别。数据集分为训练集（60,000 样本）和测试集（10,000 样本）。从训练集中进一步划分出 20%（12,000 样本）作为验证集。对图像数据进行预处理，归一化像素值至 [0, 1] 区间，以提高模型训练的稳定性和收敛速度。

### 4.2 训练流程

实现随机梯度下降（SGD）优化器，并引入动量以加速收敛。初始学习率设定为 0.0001。每个 epoch 结束后，在验证集上评估模型性能。

### 4.3 参数调优

通过网格搜索法调整以下超参数：
- **学习率**：[0.01, 0.001, 0.0001]
- **隐藏层大小**：[50, 100, 150]
- **正则化强度**：[0.001, 0.01, 0.1]


